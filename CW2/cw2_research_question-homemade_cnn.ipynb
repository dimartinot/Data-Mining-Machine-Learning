{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#F21DL-Data-Mining-&amp;-Machine-Learning\" data-toc-modified-id=\"F21DL-Data-Mining-&amp;-Machine-Learning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>F21DL Data Mining &amp; Machine Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Coursework-2-:--Convolutional-Network-for-Image-Classification\" data-toc-modified-id=\"Coursework-2-:--Convolutional-Network-for-Image-Classification-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Coursework 2 :  Convolutional Network for Image Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-constants\" data-toc-modified-id=\"Imports-&amp;-constants-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Imports &amp; constants</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F21DL Data Mining & Machine Learning\n",
    "\n",
    "## Coursework 2 :  Convolutional Network for Image Classification\n",
    "---\n",
    "*ACCAD Dimitri, AUZIMOUR Antoine, DELTEL Clarence, DI MARTINO Thomas*\n",
    "\n",
    "This notebook presents our work in the research question. \n",
    "In our research work, we wanted to benchmark the performances of a more common Deep Learning algorithm used to deal with data that have an architecture in it, whether it is spatial or temporal: the convolutional neural networks.\n",
    "\n",
    "<figure style=\"margin-top, margin-bottom:10px; text-align: center\">\n",
    "        <img src=\"https://www.learnopencv.com/wp-content/uploads/2017/11/convolution-example-matrix.gif\">\n",
    "    <figcaption style=\"display:block;margin-left:auto;margin-right:auto\"><u>Animation of the convolutional process (source: <a href=\"https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/\">link</a>)</u></figcaption>\n",
    "</figure>\n",
    "\n",
    "These neural networks use the process of convolution (c.f. above) to generate <b>features maps</b> that are dense in information and that can help a classifier to have more ease to find the correct class.\n",
    "\n",
    "This process of extracting features from images is transferable to a lot of different tasks: given a dataset where we want to discriminate cats from dogs, cars from motorcycles, a CNN will always look for patterns, more or less complex, depending on the depth of the network, that makeup any object (it could be a line, a curve, a round, gaps in colors...). This is the combination of these objects that leads a CNN to detect a given object in an image.\n",
    "\n",
    "In this notebook, we do not use Transfer Learning, we just developed a simple CNN with its convolutional and fully-connected layers.\n",
    "\n",
    "Now for the code part !\n",
    "\n",
    "### Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MAIN IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "# KERAS IMPORTS\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Conv2D, Dropout, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# SKLEARN IMPORTS\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "ORIGINAL_IMAGE_SHAPE = (48, 48)\n",
    "VGG_IMAGE_SHAPE = (224,224)\n",
    "NUM_CLASSES = 10\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 4\n",
    "SEED = 42\n",
    "IMG_FOLDER = \"data\"\n",
    "ROOT_FOLDER = os.getcwd()\n",
    "NB_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier for Keras to work with the images, we will save all of them as real .png file in a data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_to_disk(PATH_TO_CSV=\"x_train_gr_smpl.csv\", PATH_TO_DISK=\"data\"):\n",
    "    print(\"Opening csv..\")\n",
    "    data = pd.read_csv(PATH_TO_CSV)\n",
    "    print(\"Csv opened..\")\n",
    "    print(\"Saving images to {}\".format(os.path.join(os.getcwd(),PATH_TO_DISK)))\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        np_row = row.to_numpy()\n",
    "        img = np_row.reshape(ORIGINAL_IMAGE_SHAPE).astype(np.float32)\n",
    "        cv2_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.imwrite(\n",
    "            os.path.join(os.path.join(os.getcwd(),PATH_TO_DISK), f\"img{index}.png\"),#path to img\n",
    "            cv2_img\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from_csv_to_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the useful classes for our problem:\n",
    " - The model class that we will use to interact with our model\n",
    " - The Generator Keras object that will provide data to our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(dataframe, path_column_name=\"imgpath\", class_column_name=\"class\", is_test = False):\n",
    "    \"\"\"\n",
    "    Dataframe should contain two columns:\n",
    "     - img path column (default name: 'imgpath')\n",
    "     - img class column (default name: 'class')\n",
    "     \n",
    "    If is_test: return a single generator\n",
    "    If is_test is False: return a tuple of train and val datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if (is_test):\n",
    "        \n",
    "        generator = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        test_generator = generator.flow_from_dataframe(\n",
    "            directory=os.path.join(ROOT_FOLDER, IMG_FOLDER),\n",
    "            shuffle=False,\n",
    "            dataframe=dataframe,  \n",
    "            x_col=path_column_name, \n",
    "            y_col=class_column_name, \n",
    "            class_mode=\"categorical\", \n",
    "            target_size=ORIGINAL_IMAGE_SHAPE,\n",
    "            color_mode=\"rgb\", #the last two parameters induce the resizing to (224,224,3)\n",
    "            seed=SEED\n",
    "        )\n",
    "        \n",
    "        return test_generator\n",
    "    \n",
    "    else:      \n",
    "    \n",
    "        generator = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.2, # set validation split\n",
    "            #data augmentation\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        train_generator = generator.flow_from_dataframe(\n",
    "            directory=os.path.join(ROOT_FOLDER, IMG_FOLDER),\n",
    "            dataframe=dataframe,  \n",
    "            x_col=path_column_name, \n",
    "            y_col=class_column_name, \n",
    "            class_mode=\"categorical\", \n",
    "            target_size=ORIGINAL_IMAGE_SHAPE,\n",
    "            color_mode=\"rgb\", #the last two parameters induce the resizing to (224,224,3)\n",
    "            batch_size=BATCH_SIZE,\n",
    "            seed=SEED,\n",
    "            subset='training') \n",
    "\n",
    "        validation_generator = generator.flow_from_dataframe(\n",
    "            directory=os.path.join(ROOT_FOLDER, IMG_FOLDER),\n",
    "            dataframe=dataframe,  \n",
    "            x_col=path_column_name, \n",
    "            y_col=class_column_name, \n",
    "            class_mode=\"categorical\", \n",
    "            target_size=ORIGINAL_IMAGE_SHAPE,\n",
    "            color_mode=\"rgb\", #the last two parameters induce the resizing to (224,224,3)\n",
    "            batch_size=BATCH_SIZE,\n",
    "            seed=SEED,\n",
    "            subset='validation') \n",
    "    \n",
    "        return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        x = Input(shape = ORIGINAL_IMAGE_SHAPE + (3,))\n",
    "        \n",
    "        y = Conv2D(16,kernel_size=(3,3), activation='relu')(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        \n",
    "        y = Conv2D(32,kernel_size=(3,3), activation='relu')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = MaxPooling2D(pool_size=(2, 2))(y)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        y = Conv2D(32,kernel_size=(3,3), activation='relu')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        \n",
    "        y = Conv2D(16,kernel_size=(3,3), activation='relu')(y)\n",
    "        y = MaxPooling2D(pool_size=(2, 2))(y)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        y = Flatten()(y)\n",
    "        \n",
    "        y = Dense(1024, activation=\"relu\")(y)\n",
    "        y = Dropout(0.3)(y)\n",
    "        y = Dense(256, activation=\"relu\")(y)\n",
    "        y = Dropout(0.3)(y)\n",
    "        y = Dense(64, activation=\"relu\")(y)\n",
    "        y = Dropout(0.3)(y)\n",
    "        y = Dense(NUM_CLASSES, activation=\"softmax\")(y)\n",
    "        self.model = Model(x, y)\n",
    "        \n",
    "        opt = Adam(learning_rate=LR)\n",
    "        \n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "        \n",
    "    def train(self, datagen):\n",
    "        \"\"\"\n",
    "        Make sure to create the datagen object with the 'get_generator' method: it should be a tuple of training and validation generators\n",
    "        \"\"\"\n",
    "        train_gen, val_gen = datagen\n",
    "        \n",
    "        filepath=\"cnn-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "        \n",
    "        return self.model.fit_generator(    \n",
    "            train_gen,\n",
    "            epochs=NB_EPOCHS,\n",
    "            steps_per_epoch = train_gen.samples,\n",
    "            validation_data = val_gen, \n",
    "            validation_steps = val_gen.samples,\n",
    "            verbose=0, \n",
    "            callbacks=[\n",
    "                TQDMNotebookCallback(), \n",
    "                checkpoint,\n",
    "                TensorBoard(\n",
    "                    log_dir='.\\\\logs', histogram_freq=1, batch_size=BATCH_SIZE, write_graph=True, write_grads=True, write_images=True, update_freq='epoch'\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def test(self, datagen, steps=1):\n",
    "        \"\"\"\n",
    "        Make sure to create the datagen object with the 'get_generator' method\n",
    "        \"\"\"\n",
    "        return self.model.evaluate_generator(datagen, steps=steps)\n",
    "    \n",
    "    def predict(self, datagen):\n",
    "        \"\"\"\n",
    "        Make sure to create the datagen object with the 'get_generator' method        \n",
    "        \"\"\"\n",
    "        return self.model.predict_generator(datagen)\n",
    "    \n",
    "    def load_from_fileweights(self, path):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model.load_weights(os.path.join(os.getcwd(), path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load data and launching training sessions using the same 10-fold validation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = np.array(\n",
    "                sorted(os.listdir(os.path.join(ROOT_FOLDER, IMG_FOLDER)), \n",
    "                     key=lambda x: eval(x[3:][:-4])# we sort images with their index number\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_csv(\"y_train_smpl.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgpath</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>img0.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>img1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>img2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>img3.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>img4.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    imgpath class\n",
       "0  img0.png     0\n",
       "1  img1.png     0\n",
       "2  img2.png     0\n",
       "3  img3.png     0\n",
       "4  img4.png     0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.DataFrame(classes)\n",
    "c = c.astype(str)\n",
    "df = pd.concat([pd.DataFrame(np.expand_dims(images_path, axis=1)), c], axis=1)\n",
    "df.columns = [\"imgpath\", \"class\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe has now the correct information, we can create the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8103 validated image filenames belonging to 10 classes.\n",
      "Found 2025 validated image filenames belonging to 10 classes.\n",
      "Found 2532 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"imgpath\"], df[\"class\"], test_size=0.20, random_state=SEED)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "datagen_train = get_generator(train_df) # tuple (train_gen, val_ge)\n",
    "datagen_test = get_generator(test_df, is_test=True) # single generator for test\n",
    "\n",
    "model.load_from_fileweights(\"cnn-08-0.99.hdf5\")\n",
    "\n",
    "#hist = model.train(datagen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tTested metrics are: ['loss', 'accuracy']\n",
      "\t\tPerf:  [0.00017992999346461147, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\tTested metrics are:\", model.model.metrics_names)\n",
    "print(\"\\t\\tPerf: \",model.test(datagen_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(datagen_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test performances of our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>precision</td>\n",
       "      <td>0.996337</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980926</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.986971</td>\n",
       "      <td>0.989597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall</td>\n",
       "      <td>0.947735</td>\n",
       "      <td>0.997409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>0.995134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.988870</td>\n",
       "      <td>0.989336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996198</td>\n",
       "      <td>0.997561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.948148</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.987783</td>\n",
       "      <td>0.989341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>support</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>465.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>2532.000000</td>\n",
       "      <td>2532.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1     2           3           4      5      6  \\\n",
       "precision    0.996337    0.964912   1.0    1.000000    1.000000    1.0    1.0   \n",
       "recall       0.947735    0.997409   1.0    0.992424    0.995134    1.0    1.0   \n",
       "f1-score     0.971429    0.980892   1.0    0.996198    0.997561    1.0    1.0   \n",
       "support    287.000000  386.000000  87.0  264.000000  411.000000  465.0  157.0   \n",
       "\n",
       "              7           8          9  accuracy    macro avg  weighted avg  \n",
       "precision   1.0    0.980926   0.927536  0.989336     0.986971      0.989597  \n",
       "recall      1.0    0.986301   0.969697  0.989336     0.988870      0.989336  \n",
       "f1-score    1.0    0.983607   0.948148  0.989336     0.987783      0.989341  \n",
       "support    44.0  365.000000  66.000000  0.989336  2532.000000   2532.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics.classification_report(y_test,np.argmax(y_pred, axis=1).astype(str) ,  output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86869"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df\n",
    "del test_df\n",
    "del model\n",
    "from keras import backend as K\n",
    "import gc\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
